{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Experiment on MNIST data - \n",
    "The task is to reconstruct ground truth pixels using pixels+noise\n",
    "If prior knowledge of the required topology is provided then we will observe the same data\n",
    "being predicted as a 0, 9, 8 etc. as different priors are enforced. \n",
    "\"\"\"\n",
    "\n",
    "import copy\n",
    "import gudhi as gd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.fft as ft\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchsummary\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from models import Segmenter_Unet, MNIST_classifier\n",
    "\n",
    "from topologylayer.nn import LevelSetLayer2D, TopKBarcodeLengths\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./MNIST_data', train=True, download=True, transform=None)\n",
    "mnist_testset = datasets.MNIST(root='./MNIST_data', train=False, download=True, transform=None)\n",
    "img_dim = 28\n",
    "print(\"Size of training set is {}\".format(len(mnist_trainset)))\n",
    "print(\"Size of test set is {}\".format(len(mnist_testset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Split training set \"\"\"\n",
    "\n",
    "X_train = np.array([np.array(x[0]) for x in mnist_trainset])\n",
    "Y_train = np.array([x[1] for x in mnist_trainset])\n",
    "X_test = np.array([np.array(x[0]) for x in mnist_testset])\n",
    "Y_test = np.array([x[1] for x in mnist_testset])\n",
    "\n",
    "# use some of the training set to train denoising network\n",
    "# use some of the training set to train digit classifier (that can measure how well digits are denoised)\n",
    "N_denoise = 10000\n",
    "N_classifier = 50000\n",
    "\n",
    "X_denoise = X_train[:N_denoise]\n",
    "Y_denoise = Y_train[:N_denoise]\n",
    "X_classifier = X_train[N_denoise:N_denoise+N_classifier]\n",
    "Y_classifier = Y_train[N_denoise:N_denoise+N_classifier]\n",
    "\n",
    "def norm(X):\n",
    "    return X.astype(np.float) / np.max(X, axis=(1,2)).reshape((-1, 1, 1))\n",
    "\n",
    "X_denoise = norm(X_denoise)\n",
    "X_classifier = norm(X_classifier)\n",
    "\n",
    "print(X_denoise.shape)\n",
    "print(Y_denoise.shape)\n",
    "print(X_classifier.shape)\n",
    "print(Y_classifier.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier_net = MNIST_classifier(img_dim).to(device)\n",
    "classifier_optimizer = optim.Adam(classifier_net.parameters(), lr=1e-4)\n",
    "\n",
    "X_classifier_torch = torch.tensor(X_classifier.reshape(-1, 1, img_dim, img_dim)).float().to(device)\n",
    "Y_classifier_torch = torch.tensor(Y_classifier).to(device)\n",
    "\n",
    "N_classifier_val = 10000\n",
    "N_classifier_train = N_classifier - N_classifier_val\n",
    "\n",
    "def train_classifier(model, optimizer, X, Y, X_v, Y_v, batch_size=50, num_epochs=1, verbose=False):\n",
    "    \"\"\" Train the classification model\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    N = X.shape[0]\n",
    "    if Y.shape[0] != N:\n",
    "        raise ValueError('ERROR: Number of labels ({}) != Number of images ({})!'.format(Y.shape[0], N))\n",
    "\n",
    "    num_batches = N // batch_size\n",
    "    for e in range(num_epochs):\n",
    "        train_loss = 0.\n",
    "        batch_indices = np.arange(N, dtype=np.int)\n",
    "        np.random.shuffle(batch_indices)\n",
    "\n",
    "        for b in range(num_batches):\n",
    "            this_batch_indices = batch_indices[b*batch_size:(b+1)*batch_size]\n",
    "            X_batch = X[this_batch_indices]\n",
    "            Y_batch = Y[this_batch_indices]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predict_batch = model(X_batch)\n",
    "            ce_loss = torch.nn.CrossEntropyLoss()(predict_batch, Y_batch)\n",
    "            train_loss += ce_loss.item()\n",
    "            ce_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        if ((e+1) % 5) == 0:\n",
    "            # check validation loss as well\n",
    "            model.eval()\n",
    "            predict_val = model(X_v)\n",
    "            validation_loss = torch.nn.CrossEntropyLoss()(predict_val, Y_v)\n",
    "            validation_accuracy = torch.mean((Y_v == torch.argmax(predict_val, dim=1)).float()) * 100.\n",
    "            \n",
    "            if verbose:\n",
    "                print('Epoch: {0:5d} \\t Training Loss: {1:5g} \\t Val Loss: {2:5g} \\t Val Acc: {3:4g}%'.format(e+1,\n",
    "                                                                                     train_loss / num_batches,\n",
    "                                                                                     validation_loss,\n",
    "                                                                                     validation_accuracy))\n",
    "            # set model back into training mode\n",
    "            model.train()\n",
    "\n",
    "    return model\n",
    "\n",
    "torchsummary.summary(classifier_net, (1, img_dim, img_dim))\n",
    "\n",
    "batch_size = 1000\n",
    "num_epochs = 250\n",
    "\n",
    "try:\n",
    "    classifier_net = torch.load('./MNIST_classifier.pt')\n",
    "except:\n",
    "    classifier_net = train_classifier(classifier_net,\n",
    "                                      classifier_optimizer,\n",
    "                                      X_classifier_torch[:N_classifier_train],\n",
    "                                      Y_classifier_torch[:N_classifier_train],\n",
    "                                      X_classifier_torch[N_classifier_train:N_classifier_train+N_classifier_val],\n",
    "                                      Y_classifier_torch[N_classifier_train:N_classifier_train+N_classifier_val],\n",
    "                                      batch_size,\n",
    "                                      num_epochs,\n",
    "                                      verbose=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.save(classifier_net, './MNIST_classifier.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Add noise to MNIST digits in the Fourier domain \"\"\"\n",
    "def add_noise(X, num_lines_removed):\n",
    "    N = X.shape[0]\n",
    "    K = ft.fftshift(ft.fft2(X), axes=(1,2))\n",
    "    num_img = K.shape[0]\n",
    "    img_dim = K.shape[-1]\n",
    "    K_degraded = K.copy()\n",
    "    \n",
    "    for n in range(num_img):\n",
    "        lines = np.arange(img_dim)\n",
    "        \n",
    "        np.random.shuffle(lines)\n",
    "        for l in lines[:num_lines_removed]:\n",
    "            K_degraded[n, l] = 0\n",
    "        \n",
    "        np.random.shuffle(lines)\n",
    "        for l in lines[:num_lines_removed]:\n",
    "            K_degraded[n, :, l] = 0\n",
    "        \n",
    "    X_recon = np.abs(ft.ifft2(K_degraded))\n",
    "    # min already 0 due to np.abs\n",
    "    X_recon = X_recon / np.max(X_recon, axis=(1,2)).reshape((N, 1, 1))\n",
    "    return X_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train network to get original images back - then train one with digit-specific topological priors \"\"\"\n",
    "\n",
    "def train_model_supervised(model, optimizer, X, Y, X_v, Y_v, batch_size=50, num_epochs=1, verbose=False):\n",
    "    \"\"\" Train the segmentation model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model - Pytorch model\n",
    "    optimizer - Pytorch optimizer\n",
    "    X - training images\n",
    "    Y - training labels\n",
    "    X_v - validation images\n",
    "    Y_v - validation labels\n",
    "    batch_size - int - batch size for training\n",
    "    num_epochs - int - number of full epochs to train for\n",
    "    verbose - bool - if True, print training information\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model - trained Pytorch model\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    N = X.shape[0]\n",
    "    if Y.shape[0] != N:\n",
    "        raise ValueError('ERROR: Number of labels ({}) != Number of images ({})!'.format(Y.shape[0], N))\n",
    "\n",
    "    num_batches = N // batch_size\n",
    "    for e in range(num_epochs):\n",
    "        train_loss = 0.\n",
    "        batch_indices = np.arange(N, dtype=np.int)\n",
    "        np.random.shuffle(batch_indices)\n",
    "\n",
    "        for b in range(num_batches):\n",
    "            this_batch_indices = batch_indices[b*batch_size:(b+1)*batch_size]\n",
    "            X_batch = X[this_batch_indices]\n",
    "            Y_batch = Y[this_batch_indices]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predict_batch = model(X_batch)\n",
    "            bce_loss = F.binary_cross_entropy(predict_batch, Y_batch)\n",
    "            train_loss += bce_loss.item()\n",
    "            bce_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        if ((e+1) % 10) == 0:\n",
    "            # check validation loss as well\n",
    "            model.eval()\n",
    "            predict_val = model(X_v)\n",
    "            validation_loss = nn.MSELoss()(predict_val, Y_v)\n",
    "            \n",
    "            if verbose:\n",
    "                print('Epoch: {0:5d} \\t Training Loss: {1:5g} \\t Validation Loss: {2:5g}'.format(e+1,\n",
    "                                                                                     train_loss / num_batches,\n",
    "                                                                                     validation_loss))\n",
    "            model.train()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Create noisy images\"\"\"\n",
    "l = 8\n",
    "X_noise = add_noise(X_denoise, l)   \n",
    "X_noise_torch = torch.tensor(X_noise.reshape(-1, 1, img_dim, img_dim)).float().to(device)\n",
    "X_denoise_torch = torch.tensor(X_denoise.reshape(-1, 1, img_dim, img_dim)).float().to(device)\n",
    "\n",
    "X_test_noise = add_noise(X_test, l)\n",
    "X_test_noise_torch = torch.tensor(X_test_noise.reshape(-1, 1, img_dim, img_dim)).float().to(device)\n",
    "X_test_torch = torch.tensor(X_test.reshape(-1, 1, img_dim, img_dim)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Train U-net to denoise the MNIST images \"\"\"\n",
    "N_denoise_train = 100\n",
    "N_denoise_val = 100\n",
    "\n",
    "model = Segmenter_Unet(img_dim=img_dim,\n",
    "                     num_filters=16)\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "model = train_model_supervised(model, optimizer,\n",
    "                X_noise_torch[:N_denoise_train],\n",
    "                X_denoise_torch[:N_denoise_train],\n",
    "                X_noise_torch[N_denoise_train:N_denoise_train+N_denoise_val],\n",
    "                X_denoise_torch[N_denoise_train:N_denoise_train+N_denoise_val],\n",
    "                batch_size=min(1000, N_denoise_train), num_epochs=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Predict on test set \"\"\"\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Z_predicted = model(X_test_noise_torch)\n",
    "Z_predicted_np = Z_predicted.cpu().numpy()[:,0]\n",
    "print(Z_predicted_np.shape)\n",
    "print(X_test_noise_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Assess quality of reconstructed images by passing them through pre-trained MNIST classifier\n",
    "if the classifier can correctly tell what they are then they look good, since it is ~98% accurate on real digits \"\"\"\n",
    "Y_test_torch = torch.tensor(Y_test)\n",
    "Z_digit_prediction = classifier_net(Z_predicted)\n",
    "X_noise_digit_prediction = classifier_net(X_test_noise_torch)\n",
    "X_digit_prediction = classifier_net(X_test_torch)\n",
    "print(Z_digit_prediction.shape)\n",
    "print(X_noise_digit_prediction.shape)\n",
    "print(X_digit_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.mean((torch.argmax(X_noise_digit_prediction, dim=1).cpu() == Y_test_torch).float()))\n",
    "print(torch.mean((torch.argmax(X_digit_prediction, dim=1).cpu() == Y_test_torch).float()))\n",
    "print(torch.mean((torch.argmax(Z_digit_prediction, dim=1).cpu() == Y_test_torch).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Optimise topological loss on a single case to get some nice pictures for the paper\n",
    "train network with some specific set of parameters, then observe change in output reconstruction\n",
    "when topological priors are applied to the output and the network's weights adjusted \"\"\" \n",
    "\n",
    "H_1 = {0:1, 1:0} # 1, 2, 3, 4, 5, 7\n",
    "H_0 = {0:1, 1:1} # 0, 6, 9\n",
    "H_8 = {0:1, 1:2} # 8\n",
    "\n",
    "# correct topology for each digit\n",
    "H_dict = {0:H_0,\n",
    "          1:H_1,\n",
    "          2:H_1, # note this will close the loop on the 2 - some interesting cases here?\n",
    "          3:H_1,\n",
    "          4:H_1,\n",
    "          5:H_1,\n",
    "          6:H_0,\n",
    "          7:H_1,\n",
    "          8:H_8,\n",
    "          9:H_0}\n",
    "\n",
    "dgminfo = LevelSetLayer2D(size=(28,28), sublevel=False, maxdim=1)\n",
    "l2_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_network_correct = torch.argmax(Z_digit_prediction, dim=1).cpu() == Y_test_torch\n",
    "print(original_network_correct[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "f = plt.figure(figsize=(15,5))\n",
    "(ax1, ax2, ax3) = f.subplots(1,3)\n",
    "ax1.imshow(X_test_noise[i])\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax2.imshow(X_test[i])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax3.imshow(Z_predicted_np[i])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "print('Ground truth: {}'.format(Y_test[i]))\n",
    "print('Predicted as: {}'.format(torch.argmax(Z_digit_prediction[i]).item()))\n",
    "print('Logits:')\n",
    "print(Z_digit_prediction[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_topo = copy.deepcopy(model)\n",
    "optimizer = torch.optim.Adam(model_topo.parameters(), lr=1e-5)\n",
    "num_iter_topo = 100\n",
    "digit_i = Y_test[i]\n",
    "H_i = H_dict[digit_i]\n",
    "\n",
    "print(digit_i)\n",
    "print(H_i)\n",
    "\n",
    "original_model_output = model(X_test_noise_torch[i:i+1]).cpu().detach() # detach to avoid second pass error\n",
    "\n",
    "L_sqdiff_weight = 10 # hyper-parameter\n",
    "max_k = 20 # only consider this many bars - most will be 0-length anyway\n",
    "\n",
    "L_list = []\n",
    "for t in range(num_iter_topo):\n",
    "    optimizer.zero_grad()\n",
    "    Z_cuda = model_topo(X_test_noise_torch[i:i+1])\n",
    "    Z_cpu = Z_cuda.cpu()\n",
    "    a = dgminfo(Z_cpu)\n",
    "\n",
    "    L0 = (TopKBarcodeLengths(dim=0, k=max_k)(a)**2).sum()\n",
    "    dim_1_sq_bars = TopKBarcodeLengths(dim=1, k=max_k)(a)**2\n",
    "    bar_signs = torch.ones(max_k)\n",
    "    bar_signs[:H_i[1]] = -1\n",
    "    L1 = (dim_1_sq_bars * bar_signs).sum()\n",
    "\n",
    "    L_sqdiff = l2_loss(original_model_output, Z_cpu) * L_sqdiff_weight\n",
    "    L = L0 + L1 + L_sqdiff\n",
    "    L.backward()\n",
    "    L_list.append(L.item())\n",
    "    optimizer.step()\n",
    "\n",
    "    ground_truth_mask = X_test_torch[i:i+1][0,0].cpu().detach()\n",
    "    original_predicted_mask = original_model_output[0,0]\n",
    "    topo_predicted_mask = Z_cpu[0,0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(20,5))\n",
    "(ax1, ax2, ax3, ax4) = f.subplots(1,4)\n",
    "ax1.imshow(X_test_noise[i])\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax2.imshow(X_test[i])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax3.imshow(Z_predicted_np[i])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_yticks([])\n",
    "ax4.imshow(Z_cpu[0,0].detach().numpy(), cmap='gray')\n",
    "ax4.set_xticks([])\n",
    "ax4.set_yticks([])\n",
    "\n",
    "Z_topo_digit_prediction_i = classifier_net(Z_cuda)\n",
    "\n",
    "print(Y_test[i])\n",
    "print(torch.argmax(Z_topo_digit_prediction_i).item())\n",
    "print(Z_topo_digit_prediction_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_tidy(diag, eps=1e-1):\n",
    "    new_diag = []\n",
    "    for _, x in diag:\n",
    "        if np.abs(x[0] - x[1]) > eps:\n",
    "            new_diag.append((_, x))\n",
    "    return new_diag\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(Z_predicted_np[i], cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "cc = gd.CubicalComplex(dimensions=(img_dim, img_dim),\n",
    "               top_dimensional_cells=1-Z_predicted_np[i].flatten())\n",
    "\n",
    "diag = cc.persistence()\n",
    "plt.figure(figsize=(3,3))\n",
    "diag_clean = diag_tidy(diag, 1e-3)\n",
    "gd.plot_persistence_barcode(diag_clean)\n",
    "plt.ylim(-1, len(diag_clean))\n",
    "plt.xticks(ticks=np.linspace(0, 1, 6), labels=np.round(np.linspace(1, 0, 6), 2))\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(Z_cpu[0,0].detach().numpy(), cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "cc = gd.CubicalComplex(dimensions=(img_dim, img_dim),\n",
    "               top_dimensional_cells=1-Z_cpu[0,0].detach().numpy().flatten())\n",
    "diag = cc.persistence()\n",
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "diag_clean = diag_tidy(diag, 1e-3)\n",
    "gd.plot_persistence_barcode(diag_clean)\n",
    "plt.ylim(-1, len(diag_clean))\n",
    "plt.xticks(ticks=np.linspace(0, 1, 6), labels=np.round(np.linspace(1, 0, 6), 2))\n",
    "plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
